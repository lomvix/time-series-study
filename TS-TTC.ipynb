{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference:  \n",
    "> [TS-TCC: 通过Temporal和Contextual对比学习的经典之作](https://mp.weixin.qq.com/s/rsSBssZK4iWDt-aZwhAUaQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据增强：\n",
    "# 1、强增强：jitter-and-scale，jitter是通过在数据点上添加小幅度的随机变化，scale是随机调整数据点的数值幅度；\n",
    "# 2、弱增强：permutation-and-jitter，permutation是将信号分割成随机数量的片段（最多M个），然后随机打乱这些片段的顺序。\n",
    "\n",
    "\n",
    "def jitter(x, sigma=0.8):    \n",
    "    # https://arxiv.org/pdf/1706.00527.pdf    \n",
    "    return x + np.random.normal(loc=0., scale=sigma, size=x.shape)\n",
    "\n",
    "def scaling(x, sigma=1.1):      \n",
    "    factor = np.random.normal(loc=2., scale=sigma, size=(x.shape[0], x.shape[2]))    \n",
    "    ai = []    \n",
    "    for i in range(x.shape[1]):        \n",
    "        xi = x[:, i, :]        \n",
    "        ai.append(np.multiply(xi, factor[:, :])[:, np.newaxis, :])    \n",
    "        return np.concatenate((ai), axis=1)\n",
    "\n",
    "def permutation(x, max_segments=5, seg_mode=\"random\"):    \n",
    "    orig_steps = np.arange(x.shape[2])\n",
    "    num_segs = np.random.randint(1, max_segments, size=(x.shape[0]))\n",
    "    ret = np.zeros_like(x)    \n",
    "    for i, pat in enumerate(x):        \n",
    "        if num_segs[i] > 1:            \n",
    "            if seg_mode == \"random\":                \n",
    "                split_points = np.random.choice(x.shape[2] - 2, num_segs[i] - 1, replace=False)                \n",
    "                split_points.sort()                \n",
    "                splits = np.split(orig_steps, split_points)            \n",
    "            else:                \n",
    "                splits = np.array_split(orig_steps, num_segs[i])            \n",
    "                warp = np.concatenate(np.random.permutation(splits)).ravel()            \n",
    "                ret[i] = pat[0,warp]        \n",
    "        else:            \n",
    "            ret[i] = pat    \n",
    "    return torch.from_numpy(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data, labels, aug1, aug2) in enumerate(train_loader):    \n",
    "    # send to device    \n",
    "    # 数据增强后的数据    \n",
    "    data, labels = data.float().to(device), labels.long().to(device)    \n",
    "    aug1, aug2 = aug1.float().to(device), aug2.float().to(device)\n",
    "    # optimizer    \n",
    "    model_optimizer.zero_grad()    \n",
    "    temp_cont_optimizer.zero_grad()\n",
    "    if training_mode == \"self_supervised\":        \n",
    "        # 喂入Encoder获取时序特征        \n",
    "        predictions1, features1 = model(aug1)        \n",
    "        predictions2, features2 = model(aug2)\n",
    "        # normalize projection feature vectors        # 标准化        \n",
    "        features1 = F.normalize(features1, dim=1)        \n",
    "        features2 = F.normalize(features2, dim=1)                \n",
    "        # 2边支路各自预测对方的未来特征值        \n",
    "        temp_cont_loss1, temp_cont_lstm_feat1 = temporal_contr_model(features1, features2)        \n",
    "        temp_cont_loss2, temp_cont_lstm_feat2 = temporal_contr_model(features2, features1)\n",
    "        # normalize projection feature vectors        \n",
    "        zis = temp_cont_lstm_feat1         \n",
    "        zjs = temp_cont_lstm_feat2 \n",
    "    else:        \n",
    "        output = model(data)\n",
    "    # compute loss    \n",
    "    if training_mode == \"self_supervised\":        \n",
    "        # 计算损失        \n",
    "        lambda1 = 1        \n",
    "        lambda2 = 0.7        \n",
    "        nt_xent_criterion = NTXentLoss(device, config.batch_size, config.Context_Cont.temperature,config.Context_Cont.use_cosine_similarity)        \n",
    "        loss = (temp_cont_loss1 + temp_cont_loss2) * lambda1 +  nt_xent_criterion(zis, zjs) * lambda2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq_Transformer(nn.Module):    \n",
    "    def __init__(self, *, patch_size, dim, depth, heads, mlp_dim, channels=1, dropout=0.1):        \n",
    "        super().__init__()        \n",
    "        patch_dim = channels * patch_size        \n",
    "        self.patch_to_embedding = nn.Linear(patch_dim, dim)        \n",
    "        self.c_token = nn.Parameter(torch.randn(1, 1, dim))        \n",
    "        self.transformer = Transformer(dim, depth, heads, mlp_dim, dropout)        \n",
    "        self.to_c_token = nn.Identity()\n",
    "\n",
    "    def forward(self, forward_seq):        \n",
    "        # 数据增强的序列embedding化        \n",
    "        x = self.patch_to_embedding(forward_seq)        \n",
    "        b, n, _ = x.shape        \n",
    "        # 加入c_token        \n",
    "        c_tokens = repeat(self.c_token, '() n d -> b n d', b=b)        \n",
    "        x = torch.cat((c_tokens, x), dim=1)        \n",
    "        # 进入Transformer        \n",
    "        x = self.transformer(x)        \n",
    "        # 获取c_token的隐层状态       \n",
    "        c_t = self.to_c_token(x[:, 0])        \n",
    "        return c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TC(nn.Module):    \n",
    "    def __init__(self, configs, device):        \n",
    "        super(TC, self).__init__()        \n",
    "        self.num_channels = configs.final_out_channels        \n",
    "        self.timestep = configs.TC.timesteps        \n",
    "        # 为预测的每个时间戳都构建一个线性层        \n",
    "        self.Wk = nn.ModuleList([nn.Linear(configs.TC.hidden_dim, self.num_channels) for i in range(self.timestep)])        \n",
    "        self.lsoftmax = nn.LogSoftmax()        \n",
    "        self.device = device                \n",
    "        # 图1中的非线性映射头        \n",
    "        self.projection_head = nn.Sequential(            \n",
    "            nn.Linear(configs.TC.hidden_dim, configs.final_out_channels // 2),            \n",
    "            nn.BatchNorm1d(configs.final_out_channels // 2),            \n",
    "            nn.ReLU(inplace=True),            \n",
    "            nn.Linear(configs.final_out_channels // 2, configs.final_out_channels // 4),        \n",
    "            )                \n",
    "        # Transformer模型，用于提取c        \n",
    "        self.seq_transformer = Seq_Transformer(patch_size=self.num_channels, dim=configs.TC.hidden_dim, depth=4, heads=4, mlp_dim=64)\n",
    "    def forward(self, features_aug1, features_aug2):        \n",
    "        z_aug1 = features_aug1  \n",
    "        # features are (batch_size, #channels, seq_len)        \n",
    "        seq_len = z_aug1.shape[2]        \n",
    "        z_aug1 = z_aug1.transpose(1, 2)\n",
    "        z_aug2 = features_aug2        \n",
    "        z_aug2 = z_aug2.transpose(1, 2)\n",
    "        batch = z_aug1.shape[0]        \n",
    "        # 随机选一个时间戳        \n",
    "        t_samples = torch.randint(seq_len - self.timestep, size=(1,)).long().to(self.device)  \n",
    "        # randomly pick time stamps\n",
    "        nce = 0  \n",
    "        # average over timestep and batch        \n",
    "        # # 从 features_aug2 中提取t_samples之后的“未来”样本，并存储在 encode_samples 中作为待预测的目标特征序列        \n",
    "        encode_samples = torch.empty((self.timestep, batch, self.num_channels)).float().to(self.device)        \n",
    "        for i in np.arange(1, self.timestep + 1):            \n",
    "            encode_samples[i - 1] = z_aug2[:, t_samples + i, :].view(batch, self.num_channels)        \n",
    "        # 从 features_aug2 中抽取t_samples之前的“历史样本”，进入trans并获取c        \n",
    "        forward_seq = z_aug1[:, :t_samples + 1, :]        \n",
    "        c_t = self.seq_transformer(forward_seq)                \n",
    "        # 预测对面每个时间戳的值        \n",
    "        pred = torch.empty((self.timestep, batch, self.num_channels)).float().to(self.device)        \n",
    "        for i in np.arange(0, self.timestep):            \n",
    "            linear = self.Wk[i]            \n",
    "            pred[i] = linear(c_t)        \n",
    "            # 计算预测值和真实值的nce        \n",
    "            for i in np.arange(0, self.timestep):           \n",
    "                total = torch.mm(encode_samples[i], torch.transpose(pred[i], 0, 1))            \n",
    "                nce += torch.sum(torch.diag(self.lsoftmax(total)))        \n",
    "                nce /= -1. * batch * self.timestep        \n",
    "        return nce, self.projection_head(c_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
